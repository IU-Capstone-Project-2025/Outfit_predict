{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013c81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import PointStruct\n",
    "from sklearn.metrics import ndcg_score\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a493f1a",
   "metadata": {},
   "source": [
    "## Loading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38f79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_FILE = \"dino_small_embeddings.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866b8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings_txt(path: str, outfits: bool = True):\n",
    "    \"\"\"\n",
    "    Reads embeddings from a .txt file into a Python list of dictionaries.\n",
    "    There are two modes for parsing the data: one for outfit embeddings\n",
    "    (which include `outfit_id` and `cloth_id`), and another for golden_set\n",
    "    embeddings (which only have `cloth_id`). This separation is necessary\n",
    "    due to differences in the file format's first column (identifier).\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path to the embeddings `.txt` file.\n",
    "                    Expected format for `outfits=True`: \"cloth<outfit_id>_<cloth_id> <embedding_values>...\"\n",
    "                    Expected format for `outfits=False`: \"<cloth_id>.jpg <embedding_values>...\"\n",
    "        outfits (bool): If True, the function expects and parses the 'outfits' format,\n",
    "                        extracting both `outfit_id` and `cloth_id`.\n",
    "                        If False, it expects the 'golden_set' format, extracting only `cloth_id`.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, where each dictionary represents an embedding entry.\n",
    "                    Each dictionary will contain:\n",
    "                    - \"outfit_id\" (str): Extracted outfit ID (only if `outfits` is True).\n",
    "                    - \"cloth_id\" (str): Extracted cloth ID.\n",
    "                    - \"embeddings\" (list[float]): The numerical embedding vector.\n",
    "    \"\"\"\n",
    "    embeddings_list = [] # Initialize an empty list to store the parsed embedding dictionaries\n",
    "\n",
    "    if outfits:\n",
    "        # Mode for reading outfit embeddings (expected format: \"cloth<outfit_id>_<cloth_id> ...\")\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = f.readlines() # Read all lines from the file\n",
    "            # Strip whitespace from each line and split by space.\n",
    "            # This separates the identifier string from the embedding values.\n",
    "            lines = [line.strip().split(\" \") for line in lines]\n",
    "            \n",
    "            # Iterate through each processed line (which is now a list of strings)\n",
    "            for line in lines:\n",
    "                # Extract outfit_id using regex: looks for digits after \"cloth\"\n",
    "                # Example: \"cloth123_abc\" -> outfit_id \"123\"\n",
    "                outfit_id_match = re.search(r\"cloth(\\d+)\", line[0])\n",
    "                outfit_id = outfit_id_match[1] if outfit_id_match else None\n",
    "\n",
    "                # Extract cloth_id using regex: looks for alphanumeric characters after \"cloth<digits>_\"\n",
    "                # Example: \"cloth123_abc\" -> cloth_id \"abc\"\n",
    "                cloth_id_match = re.search(r\"cloth\\d+_([\\d\\w]+)\", line[0])\n",
    "                cloth_id = cloth_id_match[1] if cloth_id_match else None\n",
    "                \n",
    "                # Append the parsed data as a dictionary to the list\n",
    "                embeddings_list.append({\n",
    "                    \"outfit_id\" : outfit_id,\n",
    "                    \"cloth_id\" : cloth_id,\n",
    "                    \"embeddings\" : [float(val) for val in line[1:]] # Convert all subsequent values to floats for the embedding vector\n",
    "                })\n",
    "        return embeddings_list\n",
    "    else:\n",
    "        # Mode for reading golden_set embeddings (expected format: \"<cloth_id>.jpg ...\")\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = f.readlines() # Read all lines from the file\n",
    "            # Strip whitespace from each line and split by space.\n",
    "            lines = [line.strip().split(\" \") for line in lines]\n",
    "        \n",
    "            # Iterate through each processed line\n",
    "            for line in lines:\n",
    "                # Extract the name (which serves as cloth_id) by removing the \".jpg\" extension\n",
    "                # Example: \"image123.jpg\" -> name \"image123\"\n",
    "                name = line[0][:-4] \n",
    "                \n",
    "                # Append the parsed data as a dictionary to the list\n",
    "                embeddings_list.append({\n",
    "                    \"cloth_id\" : name,\n",
    "                    \"embeddings\" : [float(val) for val in line[1:]] # Convert embedding values to floats\n",
    "                })\n",
    "        return embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4ee8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = read_embeddings_txt(EMBEDDINGS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "512e64a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_size = len(embeddings_dict[0][\"embeddings\"])\n",
    "vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f80e51",
   "metadata": {},
   "source": [
    "# Connecting to Qdrant Client & Initial Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be41689",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_CLOUD_URL = \"https://b0da717c-1acf-4983-8bda-2c5214327161.eu-west-2-0.aws.cloud.qdrant.io:6333\"\n",
    "QDRANT_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.aaqOk2k8NhxTemd3DPe8jwFaeYv4Xb6CX3CH2IZ40ts\"\n",
    "COLLECTION_NAME = \"outfit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25db4c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\n",
    "    url=\"http://localhost:6333\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5001af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnsw_params = models.HnswConfigDiff(\n",
    "    m = 4,\n",
    "    ef_construct = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceb0df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.collection_exists(collection_name = COLLECTION_NAME):\n",
    "    client.delete_collection(collection_name = COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cb444a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name = COLLECTION_NAME,\n",
    "        vectors_config = models.VectorParams(\n",
    "            size = vector_size,\n",
    "            distance = models.Distance.COSINE\n",
    "        ),\n",
    "        hnsw_config = models.HnswConfigDiff(\n",
    "            m = 8,\n",
    "            ef_construct = 32\n",
    "        ),\n",
    "        quantization_config=models.ScalarQuantization(\n",
    "            scalar=models.ScalarQuantizationConfig(\n",
    "                type=models.ScalarType.INT8,\n",
    "                quantile=0.95,\n",
    "                always_ram=True,\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c3aec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=None, indexed_vectors_count=0, points_count=0, segments_count=8, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=384, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=8, ef_construct=32, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=0.95, always_ram=True))), payload_schema={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(collection_name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "127458fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_embeddings_to_database(embeddings_dict, max_items: int = None, batch: int = 128):\n",
    "    \"\"\"\n",
    "    Uploads a list of embeddings (points) to a specified Qdrant collection in batches.\n",
    "    It provides real-time progress and estimated time remaining during the upload process.\n",
    "\n",
    "    Args:\n",
    "        embeddings_dict (list[dict]): A list of dictionaries, where each dictionary\n",
    "                                     contains at least \"embeddings\" (the vector)\n",
    "                                     and \"outfit_id\" (for the payload).\n",
    "                                     Expected format: [{\"outfit_id\": \"...\", \"embeddings\": [...]}, ...]\n",
    "        max_items (int, optional): The maximum number of embeddings to upload from the list.\n",
    "                                   If None, all embeddings in `embeddings_dict` will be uploaded.\n",
    "                                   Defaults to None.\n",
    "        batch (int, optional): The number of embeddings to include in each batch upload request\n",
    "                               to Qdrant. Larger batches can be more efficient but consume\n",
    "                               more memory temporarily. Defaults to 128.\n",
    "\n",
    "    Returns:\n",
    "        None: The function performs the upload operation and prints progress.\n",
    "              It does not return any value.\n",
    "    \"\"\"\n",
    "    # Determine the total number of items to upload.\n",
    "    # If max_items is not specified, upload all available embeddings.\n",
    "    if max_items is None:\n",
    "        max_items = len(embeddings_dict)\n",
    "    \n",
    "    # Initialize a list to store the time taken for each upload cycle (batch).\n",
    "    # This is used to calculate the estimated time remaining.\n",
    "    time_for_one_cycle = []\n",
    "    \n",
    "    # Calculate the total number of upload cycles (batches) needed.\n",
    "    # Note: Integer division might truncate, but the range loop handles this.\n",
    "    number_of_cycles = max_items / batch \n",
    "    \n",
    "    # Iterate through the embeddings_dict in steps of 'batch' size.\n",
    "    # 'i' represents the starting index of the current batch.\n",
    "    for i in range(0, max_items, batch):\n",
    "        t1 = time.time() # Record the start time of the current batch upload\n",
    "        \n",
    "        # Prepare the list of PointStruct objects for the current batch.\n",
    "        # Each PointStruct requires a unique 'id', the 'vector' (embedding),\n",
    "        # and an optional 'payload' (metadata).\n",
    "        points_to_upsert = [\n",
    "            PointStruct(\n",
    "                # Generate a unique UUID for each point's ID.\n",
    "                # Converting to string is necessary as Qdrant IDs are strings or integers.\n",
    "                id=str(uuid.uuid4()), \n",
    "                # Assign the embedding vector to the 'vector' field.\n",
    "                vector=item[\"embeddings\"],\n",
    "                # Store relevant metadata in the 'payload'.\n",
    "                # Here, 'outfit_id' is stored for later retrieval/filtering.\n",
    "                payload={\n",
    "                    \"outfit_id\": item[\"outfit_id\"]\n",
    "                }\n",
    "            )\n",
    "            # Slice the embeddings_dict to get the current batch of items.\n",
    "            # enumerate is used here but 'i' is the loop variable, consider if this 'i' is truly needed.\n",
    "            # The enumerate `i` in the list comprehension is actually local to the list comprehension and unused.\n",
    "            # It should just be `for item in embeddings_dict[i:i + batch]`.\n",
    "            for item in embeddings_dict[i:i + batch] \n",
    "        ]\n",
    "        \n",
    "        # Send the batch of points to Qdrant for upsertion (insert or update).\n",
    "        # 'COLLECTION_NAME' must be defined and point to your target Qdrant collection.\n",
    "        # 'wait=True' ensures that the function call blocks until Qdrant confirms the operation\n",
    "        # has been completed for this batch, which is useful for reliable uploads and timing.\n",
    "        operation_info = client.upsert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            wait=True,\n",
    "            points=points_to_upsert\n",
    "        )\n",
    "        \n",
    "        t2 = time.time() # Record the end time of the current batch upload\n",
    "        dt = round(t2 - t1, 2) # Calculate the elapsed time for this batch\n",
    "        time_for_one_cycle.append(dt) # Store the time for calculating estimated remaining time\n",
    "        \n",
    "        # Print progress and estimated time remaining.\n",
    "        # The '\\r' at the end ensures the line is overwritten in the console,\n",
    "        # creating a dynamic progress bar.\n",
    "        # Calculation for estimated time: (remaining_items / batch_size) * average_time_per_batch\n",
    "        print(f\"Progress: {100*(i / max_items):.3f}%;   \"\n",
    "              f\"Estimated time: {((max_items - i) / batch) * np.mean(time_for_one_cycle):.3f} seconds\\t\",\n",
    "              end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ae5725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.856%;   Estimated time: 0.008 seconds\t\r"
     ]
    }
   ],
   "source": [
    "upload_embeddings_to_database(embeddings_dict, batch = 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c15ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=490, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_payload_index(\n",
    "    collection_name= COLLECTION_NAME,\n",
    "    field_name = \"outfit_id\",\n",
    "    field_schema = models.PayloadSchemaType.KEYWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64e7805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing finished\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    collection_info = client.get_collection(collection_name = COLLECTION_NAME)\n",
    "    if collection_info.status == models.CollectionStatus.GREEN:\n",
    "        # Collection status is green, which means the indexing is finished\n",
    "        print('Indexing finished')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1fc98e",
   "metadata": {},
   "source": [
    "# Search similar Outfits Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c07eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar(golden_set_embeddings_path: str,\n",
    "                   client: QdrantClient,\n",
    "                   search_params: models.SearchParams,\n",
    "                   score_threshold: float = 0.7,\n",
    "                   collection_name: str = COLLECTION_NAME,\n",
    "                   num_of_outfits_to_return: int = 5):\n",
    "    \"\"\"\n",
    "    Performs a complex similarity search to find the most relevant \"outfits\"\n",
    "    from a Qdrant collection based on a \"golden set\" of wardrobe embeddings.\n",
    "    \n",
    "    The function operates in several stages:\n",
    "    1. Loads the \"golden set\" (wardrobe) embeddings.\n",
    "    2. For each item in the wardrobe, queries Qdrant to find similar individual clothing items.\n",
    "    3. Aggregates the `outfit_id`s from these similar individual items to identify candidate outfits.\n",
    "    4. For each candidate outfit, retrieves all its associated clothing items from Qdrant.\n",
    "    5. Calculates a \"total_score\" for each candidate outfit by finding the best match\n",
    "       between its items and the wardrobe items, summing their similarity scores.\n",
    "    6. Filters out outlier clothing items within an outfit that might skew scores.\n",
    "    7. Returns the top `num_of_outfits_to_return` ranked outfits.\n",
    "\n",
    "    Args:\n",
    "        golden_set_embeddings_path (str): Path to the `.txt` file containing the\n",
    "                                          embeddings of the \"golden set\" (wardrobe items).\n",
    "        client (qdrant_client.QdrantClient): An initialized Qdrant client instance.\n",
    "        search_params (models.SearchParams): Parameters for the Qdrant vector search,\n",
    "                                           e.g., `hnsw_ef` for HNSW algorithm.\n",
    "                                           For the \"control\" search, this should typically\n",
    "                                           be set with `exact=True` to represent ground truth.\n",
    "        score_threshold (float, optional): A minimum similarity score for individual\n",
    "                                           clothing items to be considered \"similar\"\n",
    "                                           when querying Qdrant. Defaults to 0.7.\n",
    "        collection_name (str, optional): The name of the Qdrant collection where outfit\n",
    "                                         clothing items are stored. Defaults to `COLLECTION_NAME`.\n",
    "        num_of_outfits_to_return (int, optional): The maximum number of top-ranked outfits\n",
    "                                                  to return. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, where each dictionary represents a ranked outfit.\n",
    "                    Each outfit dictionary contains:\n",
    "                    - \"outfit_id\" (str): The unique identifier of the outfit.\n",
    "                    - \"total_score\" (float): The aggregated similarity score for the outfit.\n",
    "                    - \"matches\" (list[dict]): Details of the best matching wardrobe-to-outfit-item pairs.\n",
    "                    Returns an empty list if no candidate outfits are found or if an error occurs.\n",
    "    \"\"\"\n",
    "    # Load the \"golden set\" (wardrobe) embeddings from the specified text file.\n",
    "    # 'outfits=False' tells read_embeddings_txt to parse it in the golden_set format.\n",
    "    wardrobe_embeddings = read_embeddings_txt(golden_set_embeddings_path, outfits=False)\n",
    "    \n",
    "    # Extract just the embedding vectors into a NumPy array for efficient matrix operations later.\n",
    "    wardrobe_embeddings_vectors = np.array([item[\"embeddings\"] for item in wardrobe_embeddings])\n",
    "\n",
    "    # Initialize a set to store unique outfit IDs found during the initial broad search.\n",
    "    # A set is used to automatically handle duplicates.\n",
    "    candidate_outfits_ids = set()\n",
    "\n",
    "    # Step 1: Initial broad search to find candidate outfits.\n",
    "    # For each embedding in the wardrobe (golden set):\n",
    "    for i in range(len(wardrobe_embeddings)):\n",
    "        # Use the current wardrobe item's embedding as the query vector.\n",
    "        query_vector = wardrobe_embeddings[i][\"embeddings\"]\n",
    "        \n",
    "        # Query Qdrant to find clothing items similar to the current wardrobe item.\n",
    "        # 'limit=50' retrieves up to 50 similar points for each wardrobe item query.\n",
    "        # 'search_params' (e.g., hnsw_ef) controls the search algorithm's behavior.\n",
    "        # 'score_threshold' filters out very dissimilar individual clothing items.\n",
    "        similar_points = client.query_points(\n",
    "            collection_name=collection_name, # Query the collection of all individual clothing items\n",
    "            query=query_vector,\n",
    "            limit=50,\n",
    "            search_params=search_params, \n",
    "            score_threshold=score_threshold\n",
    "        ).points\n",
    "        \n",
    "        # From the similar individual clothing items found, extract their associated outfit IDs.\n",
    "        for point in similar_points:\n",
    "            # Ensure the payload contains 'outfit_id' before attempting to access it.\n",
    "            if \"outfit_id\" in point.payload:\n",
    "                # Add the outfit_id to the set of candidates.\n",
    "                candidate_outfits_ids.add(point.payload[\"outfit_id\"])\n",
    "                \n",
    "    # If no candidate outfits were identified after iterating through all wardrobe items,\n",
    "    # print a message and return an empty list.\n",
    "    if not candidate_outfits_ids:\n",
    "        print(\"No candidate outfits were found.\")\n",
    "        return []\n",
    "    \n",
    "    # Initialize a list to store dictionaries of ranked outfits, including their scores and matches.\n",
    "    ranked_outfits = []\n",
    "    \n",
    "    # Step 2: Refine and score each candidate outfit.\n",
    "    # For each unique outfit_id identified in the previous step:\n",
    "    for outfit_id in candidate_outfits_ids:\n",
    "        # Retrieve all individual clothing items that belong to the current outfit.\n",
    "        # 'scroll' is used to efficiently retrieve points that match a specific filter.\n",
    "        # The filter is set to find all points where 'outfit_id' matches the current outfit_id.\n",
    "        records, next_offset = client.scroll(\n",
    "            collection_name=collection_name,\n",
    "            scroll_filter=models.Filter(\n",
    "                must=[\n",
    "                    models.FieldCondition(\n",
    "                        key=\"outfit_id\",\n",
    "                        match=models.MatchValue(value=outfit_id)\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            limit=100, # Retrieve up to 100 items per outfit. Adjust if outfits can be larger.\n",
    "            with_payload=True, # Ensure payload (metadata) is returned with each record.\n",
    "            with_vectors=True # Ensure embedding vectors are returned with each record.\n",
    "        )\n",
    "        \n",
    "        # If no records are found for an outfit ID (shouldn't happen if outfit_id came from a valid point),\n",
    "        # or if there's an issue, print an error and return.\n",
    "        if not records:\n",
    "            print(f\"No clothes for outfit_id '{outfit_id}' were found, some error occurred.\")\n",
    "            return []\n",
    "        \n",
    "        # Extract embeddings and IDs of the clothing items belonging to the current outfit.\n",
    "        outfit_item_embeddings = np.array([record.vector for record in records])\n",
    "        outfit_item_ids = [record.id for record in records]\n",
    "\n",
    "        # An outfit must consist of at least two items to be considered valid.\n",
    "        # This prevents single-item \"outfits\" from being scored.\n",
    "        if len(outfit_item_ids) < 2:\n",
    "            continue # Skip this outfit if it's too small.\n",
    "            \n",
    "        # Calculate the similarity matrix between all wardrobe item embeddings and all\n",
    "        # items in the current candidate outfit.\n",
    "        # The result is a matrix where rows are wardrobe items and columns are outfit items.\n",
    "        # Each cell (i, j) contains the dot product (similarity) between wardrobe_embeddings_vectors[i]\n",
    "        # and outfit_item_embeddings[j].\n",
    "        similarity_matrix = np.dot(wardrobe_embeddings_vectors, outfit_item_embeddings.T)\n",
    "        \n",
    "        # For each outfit item, find the wardrobe item that matches it best.\n",
    "        # `best_matches_indices` stores the index of the best-matching wardrobe item for each outfit item.\n",
    "        # `best_matches_scores` stores the similarity score of that best match.\n",
    "        best_matches_indices = np.argmax(similarity_matrix, axis=0)\n",
    "        best_matches_scores = np.max(similarity_matrix, axis=0)\n",
    "        \n",
    "        # Initialize a list to store details of the matched items within the outfit.\n",
    "        matches = []\n",
    "        \n",
    "        # Calculate the mean of the best match scores for the current outfit.\n",
    "        best_matches_mean = np.mean(best_matches_scores)\n",
    "        \n",
    "        # Iterate through each clothing item in the current outfit to process its best match.\n",
    "        for i, outfit_item_id in enumerate(outfit_item_ids):\n",
    "            # IMPORTANT CONSIDERATION: Outlier Detection based on similarity score.\n",
    "            # If an outfit item's best match score is significantly lower than the average\n",
    "            # best match score for the entire outfit, it's considered an outlier.\n",
    "            # This helps to filter out items that might be irrelevant or poorly embedded,\n",
    "            # preventing them from negatively impacting the total outfit score.\n",
    "            # The threshold (0.75 * mean) is heuristic and can be tuned.\n",
    "            if best_matches_scores[i] < best_matches_mean * 0.75:\n",
    "                # \"if some item has very low similarity score compared to others items\n",
    "                # then it means it is outlier, and probably will disturb the prediction\"\n",
    "                # This logic is based on the observation that certain item types (like boots)\n",
    "                # might inherently have lower scores, and this threshold aims to filter\n",
    "                # out items that are too dissimilar within the context of the current outfit's matches.\n",
    "                # \"boots usually have low score\" - this note explains a specific domain observation\n",
    "                # justifying the need for such an outlier filter.\n",
    "                continue # Skip this outlier item.\n",
    "            \n",
    "            # Get the index of the best-matching wardrobe item.\n",
    "            wardrobe_idx = int(best_matches_indices[i])\n",
    "            \n",
    "            # Add details of the matched pair to the 'matches' list.\n",
    "            matches.append({\n",
    "                \"wardrobe_image_index\": wardrobe_idx,\n",
    "                \"wardrobe_image_id\": wardrobe_embeddings[wardrobe_idx][\"cloth_id\"],\n",
    "                \"outfit_item_id\": str(outfit_item_id),\n",
    "                \"score\": float(best_matches_scores[i])\n",
    "            })\n",
    "        \n",
    "        # Calculate the total score for the current outfit.\n",
    "        # This is the sum of the best match scores (after potential outlier filtering).\n",
    "        # \"if we take np.mean(), for some reason it will ignore boots in the wardrobe\n",
    "        # so that it will search only for outfits with tshirt and pants\n",
    "        # given the fact that boots always have lower scores (24 vs 35 for other)\n",
    "        # we will always ignore outfits with boots\"\n",
    "        # This note explains why `np.sum` is used instead of `np.mean` for `total_score`.\n",
    "        # Using mean might inadvertently penalize outfits containing items (like boots)\n",
    "        # that naturally have lower, but still acceptable, similarity scores.\n",
    "        # Summing avoids this by favoring outfits with more relevant overall matches.\n",
    "        total_score = np.sum(best_matches_scores)\n",
    "        \n",
    "        # Append the scored outfit to the list of ranked outfits.\n",
    "        ranked_outfits.append({\n",
    "            \"outfit_id\": outfit_id,\n",
    "            \"total_score\": total_score,\n",
    "            \"matches\": matches # Include the details of the best matches\n",
    "        })\n",
    "        \n",
    "    # Sort the outfits by their 'total_score' in descending order\n",
    "    # to get the top-ranked outfits.\n",
    "    ranked_outfits.sort(key=lambda x: x[\"total_score\"], reverse=True)\n",
    "    \n",
    "    # Return only the top 'num_of_outfits_to_return' outfits.\n",
    "    return ranked_outfits[:num_of_outfits_to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7be4453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_process_metrics():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    cpu_percent = process.cpu_percent(interval = None)\n",
    "    ram_info = process.memory_info()\n",
    "    ram_used_mb = ram_info.rss / (1024 * 1024)\n",
    "    return {\"cpu_percent\": cpu_percent, \"ram_used_mb\": ram_used_mb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83bd488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_memory_usage(client: QdrantClient,\n",
    "                             collection_name: str = COLLECTION_NAME):\n",
    "    number_of_vectors = client.get_collection(collection_name = collection_name).points_count\n",
    "    vector_size_vector = client.get_collection(collection_name = collection_name).config.params.vectors.size\n",
    "    memory_size_vector = number_of_vectors * vector_size_vector * 4 * 1.5 \n",
    "    memory_size_mb_vector = memory_size_vector / (1024 * 1024)\n",
    "    \n",
    "    payload_size = number_of_vectors * 56 * 1.5\n",
    "    # 56 stands for bytes occupied by the \"outfit_id\" payload. This is actually approximate\n",
    "    payload_size_mb = payload_size / (1024 * 1024)\n",
    "    \n",
    "    return {\n",
    "        \"vectors_size_mb\": memory_size_mb_vector,\n",
    "        \"payload_size_mb\": payload_size_mb,\n",
    "        \"overall_memory_usage_mb\": memory_size_mb_vector + payload_size_mb\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e2e57e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exact_search_metrics(client: QdrantClient,\n",
    "                             golden_set_embeddings_path: str,\n",
    "                             collection_name: str = COLLECTION_NAME,\n",
    "                             k: int = 5):\n",
    "    client.update_collection(\n",
    "        collection_name = collection_name,\n",
    "        hnsw_config = models.HnswConfigDiff(\n",
    "            m = 0\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    perfmetrics_control_local_begin = get_process_metrics()\n",
    "    search_time_control_begin = time.time()\n",
    "    search_results_control = search_similar(\n",
    "            golden_set_embeddings_path=golden_set_embeddings_path,\n",
    "            client=client,\n",
    "            search_params=models.SearchParams(exact = True, quantization = models.QuantizationSearchParams(ignore = True)), \n",
    "            num_of_outfits_to_return=k\n",
    "    )\n",
    "    search_time_control_end = time.time()\n",
    "    perfmetrics_control_local_end = get_process_metrics()\n",
    "    cached_results = {\n",
    "            \"search_results_control\": search_results_control,\n",
    "            \"perfmetrics_control_local_begin\": perfmetrics_control_local_begin,\n",
    "            \"search_time_control_begin\": search_time_control_begin,\n",
    "            \"search_time_control_end\": search_time_control_end,\n",
    "            \"perfmetrics_control_local_end\": perfmetrics_control_local_end\n",
    "    }\n",
    "        \n",
    "        \n",
    "    return cached_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab84ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_for_configuration(client: QdrantClient,\n",
    "                                        golden_set_embeddings_path: str,\n",
    "                                        cached_results,\n",
    "                                        search_params_control: models.SearchParams,\n",
    "                                        search_params_test: models.SearchParams,\n",
    "                                        k: int = 5,\n",
    "                                        ):\n",
    "    \"\"\"\n",
    "    Measures search latency, accuracy metrics (Precision, Recall, NDCG), and local \n",
    "    resource usage for two different search configurations.\n",
    "\n",
    "    Args:\n",
    "        client (QdrantClient): The Qdrant client instance.\n",
    "        golden_set_embeddings_path (str): Path to the embeddings for the queries.\n",
    "        search_params_control (models.SearchParams): Search parameters for the ground truth search (should be exact=True).\n",
    "        search_params_test (models.SearchParams): Search parameters for the HNSW test search.\n",
    "        k (int): The number of top results to consider (k in @k).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing all calculated performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # --- Execute Control Search (Ground Truth) ---\n",
    "    perfmetrics_control_local_begin = cached_results[\"perfmetrics_control_local_begin\"]\n",
    "    search_time_control_begin = cached_results[\"search_time_control_begin\"]\n",
    "    search_results_control = cached_results[\"search_results_control\"]\n",
    "    search_time_control_end = cached_results[\"search_time_control_end\"]\n",
    "    perfmetrics_control_local_end = cached_results[\"perfmetrics_control_local_end\"]\n",
    "\n",
    "    \n",
    "    # --- Execute Test Search (HNSW) ---\n",
    "    perfmetrics_test_local_begin = get_process_metrics()\n",
    "    search_time_test_begin = time.time()\n",
    "    search_results_test = search_similar(\n",
    "        golden_set_embeddings_path=golden_set_embeddings_path,\n",
    "        client=client,\n",
    "        search_params=search_params_test,\n",
    "        num_of_outfits_to_return=k\n",
    "    )\n",
    "    search_time_test_end = time.time()\n",
    "    perfmetrics_test_local_end = get_process_metrics()\n",
    "    \n",
    "    # --- Extract relevant data for metric calculation ---\n",
    "    # IDs from the ground truth search results\n",
    "    ground_truth_outfit_ids = np.array([result[\"outfit_id\"] for result in search_results_control])\n",
    "    # IDs from the HNSW test search results\n",
    "    test_outfit_ids = np.array([result[\"outfit_id\"] for result in search_results_test])\n",
    "    # Scores from the HNSW test search results\n",
    "    test_scores = np.array([result[\"total_score\"] for result in search_results_test])\n",
    "    \n",
    "    # --- Calculate Accuracy Metrics ---\n",
    "    \n",
    "    # Create a binary relevance vector for the test results based on the ground truth.\n",
    "    # 1 if the test result ID is in the ground truth set, 0 otherwise.\n",
    "    y_true_relevance = np.array([1 if outfit_id in ground_truth_outfit_ids else 0 for outfit_id in test_outfit_ids])\n",
    "    y_true_relevance_2d = y_true_relevance.reshape(1, -1)\n",
    "    \n",
    "    # Reshape the test scores for scikit-learn\n",
    "    test_scores_2d = test_scores.reshape(1, -1)\n",
    "    \n",
    "    # Calculate Precision@k: fraction of retrieved documents that are relevant\n",
    "    precision_at_k = np.sum(y_true_relevance) / k\n",
    "    \n",
    "    # Calculate Recall@k: fraction of relevant documents that are retrieved\n",
    "    # Denominator is the size of the ground truth set (k in this case)\n",
    "    recall_at_k = np.sum(y_true_relevance) / len(ground_truth_outfit_ids)\n",
    "    \n",
    "    # Calculate NDCG@k: quality of the ranked list, penalizing lower-ranked relevant items\n",
    "    ndcg_at_k = ndcg_score(y_true=y_true_relevance_2d, y_score=test_scores_2d, k=k)\n",
    "    \n",
    "    # --- Calculate Time and Resource Metrics ---\n",
    "    time_elapsed_for_control = search_time_control_end - search_time_control_begin\n",
    "    time_elapsed_for_test = search_time_test_end - search_time_test_begin\n",
    "    \n",
    "    avg_cpu_perc_control = np.mean([perfmetrics_control_local_begin[\"cpu_percent\"], perfmetrics_control_local_end[\"cpu_percent\"]])\n",
    "    avg_cpu_perc_test = np.mean([perfmetrics_test_local_begin[\"cpu_percent\"], perfmetrics_test_local_end[\"cpu_percent\"]])\n",
    "    \n",
    "    avg_ram_control = np.mean([perfmetrics_control_local_begin[\"ram_used_mb\"], perfmetrics_control_local_end[\"ram_used_mb\"]])\n",
    "    avg_ram_test = np.mean([perfmetrics_test_local_begin[\"ram_used_mb\"], perfmetrics_test_local_end[\"ram_used_mb\"]])\n",
    "    \n",
    "\n",
    "    # --- Return all metrics in a clear dictionary ---\n",
    "    return {\n",
    "        \"time_elapsed_control_s\": time_elapsed_for_control,\n",
    "        \"time_elapsed_test_s\": time_elapsed_for_test,\n",
    "        \"local_cpu_perc_control_avg\": avg_cpu_perc_control,\n",
    "        \"local_cpu_perc_test_avg\": avg_cpu_perc_test,\n",
    "        \"local_ram_control_mb_avg\": avg_ram_control,\n",
    "        \"local_ram_test_mb_avg\": avg_ram_test,\n",
    "        \"precision_at_k\": precision_at_k,\n",
    "        \"recall_at_k\": recall_at_k,\n",
    "        \"ndcg_at_k\": ndcg_at_k\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87911f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_metrics = get_exact_search_metrics(client, \"dino_small_embeddings_men_casual.txt\", COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f95534e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_parameters(\n",
    "                           client: QdrantClient,\n",
    "                           golden_set_embeddings_path: str,\n",
    "                           df_list,\n",
    "                           df_types: str,\n",
    "                           collection_name: str = COLLECTION_NAME,\n",
    "                           cached_metrics = cached_metrics\n",
    "                           ):\n",
    "    dict_params_list = [df.to_dict(orient='records') for df in df_list]\n",
    "    total_number_of_combinations = sum(df.shape[0] for df in df_list)\n",
    "    all_metrics = []\n",
    "    count_passed = 0\n",
    "    times_went = [0]\n",
    "    print(f\"Starting grid search, total number of combinations: {total_number_of_combinations}\")\n",
    "    for dict_params, df_type in zip(dict_params_list, df_types):\n",
    "        for param in dict_params:\n",
    "            print(f\"<------------------ ITERATION {count_passed + 1} ------------------>\")\n",
    "            t1 = time.time()\n",
    "            print(f\"Progress: {100 * count_passed / total_number_of_combinations:.3f}%; Estimated time: {(total_number_of_combinations - count_passed) * np.mean(times_went):.3f} seconds\")\n",
    "            print(f\"Going through the following parameters: {param}\")\n",
    "            if df_type == 'binary':\n",
    "                client.update_collection(\n",
    "                    collection_name = collection_name,\n",
    "                    hnsw_config = models.HnswConfigDiff(\n",
    "                        m = param[\"m\"],\n",
    "                        ef_construct = param[\"ef_construct\"]\n",
    "                    ),\n",
    "                )\n",
    "                \n",
    "                while True:\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "                    collection_info = client.get_collection(collection_name = COLLECTION_NAME)\n",
    "                    \n",
    "                    if collection_info.status == models.CollectionStatus.GREEN:\n",
    "                        print(\"Indexing finished for these params\")\n",
    "                        break\n",
    "                    \n",
    "                metrics = calculate_metrics_for_configuration(client = client, \n",
    "                        golden_set_embeddings_path = golden_set_embeddings_path,\n",
    "                        cached_results = cached_metrics,\n",
    "                        search_params_control = models.SearchParams(hnsw_ef = param[\"hnsw_ef\"], exact = True,\n",
    "                                    quantization=models.QuantizationSearchParams(\n",
    "                                    ignore = False, rescore = param[\"rescore\"], oversampling = param[\"oversampling\"])),\n",
    "                        search_params_test = models.SearchParams(hnsw_ef = param[\"hnsw_ef\"], exact = False,\n",
    "                                    quantization=models.QuantizationSearchParams(\n",
    "                                    ignore = False, rescore = param[\"rescore\"], oversampling = param[\"oversampling\"])))                     \n",
    "\n",
    "            elif df_type == 'product':\n",
    "                \n",
    "                if param[\"compression\"] == 16:\n",
    "                    client.update_collection(\n",
    "                        collection_name = collection_name,\n",
    "                        hnsw_config = models.HnswConfigDiff(\n",
    "                            m = param[\"m\"], \n",
    "                            ef_construct = param[\"ef_construct\"]\n",
    "                        ),\n",
    "                        quantization_config=models.ProductQuantization(\n",
    "                            product=models.ProductQuantizationConfig(\n",
    "                                compression=models.CompressionRatio.X16,\n",
    "                                always_ram=True,\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                elif param[\"compression\"] == 32:\n",
    "                    client.update_collection(\n",
    "                        collection_name = collection_name,\n",
    "                        hnsw_config = models.HnswConfigDiff(\n",
    "                            m = param[\"m\"], \n",
    "                            ef_construct = param[\"ef_construct\"]\n",
    "                        ),\n",
    "                        quantization_config=models.ProductQuantization(\n",
    "                            product=models.ProductQuantizationConfig(\n",
    "                                compression=models.CompressionRatio.X32,\n",
    "                                always_ram=True,\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                elif param[\"compression\"] == 64: \n",
    "                    client.update_collection(\n",
    "                        collection_name = collection_name,\n",
    "                        hnsw_config = models.HnswConfigDiff(\n",
    "                            m = param[\"m\"], \n",
    "                            ef_construct = param[\"ef_construct\"]\n",
    "                        ),\n",
    "                        quantization_config=models.ProductQuantization(\n",
    "                            product=models.ProductQuantizationConfig(\n",
    "                                compression=models.CompressionRatio.X64,\n",
    "                                always_ram=True,\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                while True:\n",
    "                    time.sleep(3)\n",
    "                    collection_info = client.get_collection(collection_name = COLLECTION_NAME)\n",
    "                    if collection_info.status == models.CollectionStatus.GREEN:\n",
    "                        print(\"Indexing finished for these params\")\n",
    "                        break\n",
    "                    \n",
    "                metrics = calculate_metrics_for_configuration(client = client, \n",
    "                        golden_set_embeddings_path = golden_set_embeddings_path,\n",
    "                        cached_results = cached_metrics,\n",
    "                        search_params_control = models.SearchParams(hnsw_ef = param[\"hnsw_ef\"], exact = True,\n",
    "                                    quantization=models.QuantizationSearchParams(\n",
    "                                    ignore = False, rescore = param[\"rescore\"], \n",
    "                                    oversampling = param[\"oversampling\"])),\n",
    "                        search_params_test = models.SearchParams(hnsw_ef = param[\"hnsw_ef\"], exact = False,\n",
    "                                    quantization=models.QuantizationSearchParams(\n",
    "                                    ignore = False, rescore = param[\"rescore\"], \n",
    "                                    oversampling = param[\"oversampling\"])))   \n",
    "                \n",
    "            elif df_type == 'scalar':\n",
    "                    \n",
    "                client.update_collection(\n",
    "                    collection_name = collection_name,\n",
    "                    hnsw_config = models.HnswConfigDiff(\n",
    "                            m = param[\"m\"],\n",
    "                            ef_construct = param[\"ef_construct\"]\n",
    "                    ),\n",
    "                    quantization_config=models.ScalarQuantization(\n",
    "                        scalar=models.ScalarQuantizationConfig(\n",
    "                            type=models.ScalarType.INT8,\n",
    "                            quantile=param[\"quantile\"],\n",
    "                            always_ram=True,\n",
    "                        ),\n",
    "                    ),\n",
    "                )\n",
    "                \n",
    "                while True:\n",
    "                    time.sleep(3)\n",
    "                    collection_info = client.get_collection(collection_name = COLLECTION_NAME)\n",
    "                    if collection_info.status == models.CollectionStatus.GREEN:\n",
    "                        print(\"Indexing finished for these params\")\n",
    "                        break\n",
    "                    \n",
    "                metrics = calculate_metrics_for_configuration(client = client, \n",
    "                        golden_set_embeddings_path = golden_set_embeddings_path,\n",
    "                        cached_results = cached_metrics,\n",
    "                        search_params_control = models.SearchParams(hnsw_ef = param[\"hnsw_ef\"], exact = True,\n",
    "                                    quantization=models.QuantizationSearchParams(\n",
    "                                    ignore = False, rescore = param[\"rescore\"], oversampling = param[\"oversampling\"])),\n",
    "                        search_params_test = models.SearchParams(hnsw_ef = param[\"hnsw_ef\"], exact = False,\n",
    "                                    quantization=models.QuantizationSearchParams(\n",
    "                                    ignore = False, rescore = param[\"rescore\"], oversampling = param[\"oversampling\"])))    \n",
    "            \n",
    "            count_passed += 1\n",
    "            all_metrics.append({**param, **metrics})\n",
    "            t2 = time.time()\n",
    "            if count_passed == 1:\n",
    "                    times_went = []\n",
    "            dt = t2 - t1\n",
    "            times_went.append(dt) \n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd83ab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search, total number of combinations: 160\n",
      "<------------------ ITERATION 1 ------------------>\n",
      "Progress: 0.000%; Estimated time: 0.000 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 2 ------------------>\n",
      "Progress: 0.625%; Estimated time: 570.084 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 3 ------------------>\n",
      "Progress: 1.250%; Estimated time: 590.250 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 4 ------------------>\n",
      "Progress: 1.875%; Estimated time: 592.219 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 5 ------------------>\n",
      "Progress: 2.500%; Estimated time: 592.395 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 6 ------------------>\n",
      "Progress: 3.125%; Estimated time: 589.233 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 7 ------------------>\n",
      "Progress: 3.750%; Estimated time: 586.848 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 8 ------------------>\n",
      "Progress: 4.375%; Estimated time: 584.930 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 9 ------------------>\n",
      "Progress: 5.000%; Estimated time: 581.566 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 10 ------------------>\n",
      "Progress: 5.625%; Estimated time: 583.866 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 11 ------------------>\n",
      "Progress: 6.250%; Estimated time: 581.017 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 12 ------------------>\n",
      "Progress: 6.875%; Estimated time: 576.353 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 13 ------------------>\n",
      "Progress: 7.500%; Estimated time: 571.407 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 14 ------------------>\n",
      "Progress: 8.125%; Estimated time: 567.435 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 15 ------------------>\n",
      "Progress: 8.750%; Estimated time: 562.882 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 16 ------------------>\n",
      "Progress: 9.375%; Estimated time: 563.186 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 17 ------------------>\n",
      "Progress: 10.000%; Estimated time: 559.163 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 18 ------------------>\n",
      "Progress: 10.625%; Estimated time: 554.889 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 19 ------------------>\n",
      "Progress: 11.250%; Estimated time: 562.652 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 20 ------------------>\n",
      "Progress: 11.875%; Estimated time: 557.882 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 21 ------------------>\n",
      "Progress: 12.500%; Estimated time: 552.830 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 22 ------------------>\n",
      "Progress: 13.125%; Estimated time: 557.424 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 23 ------------------>\n",
      "Progress: 13.750%; Estimated time: 552.027 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 24 ------------------>\n",
      "Progress: 14.375%; Estimated time: 546.793 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 25 ------------------>\n",
      "Progress: 15.000%; Estimated time: 550.600 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 26 ------------------>\n",
      "Progress: 15.625%; Estimated time: 545.122 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 27 ------------------>\n",
      "Progress: 16.250%; Estimated time: 539.719 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 28 ------------------>\n",
      "Progress: 16.875%; Estimated time: 544.169 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 29 ------------------>\n",
      "Progress: 17.500%; Estimated time: 538.333 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 30 ------------------>\n",
      "Progress: 18.125%; Estimated time: 532.949 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 31 ------------------>\n",
      "Progress: 18.750%; Estimated time: 527.710 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 32 ------------------>\n",
      "Progress: 19.375%; Estimated time: 522.549 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 33 ------------------>\n",
      "Progress: 20.000%; Estimated time: 517.598 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 34 ------------------>\n",
      "Progress: 20.625%; Estimated time: 512.642 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 35 ------------------>\n",
      "Progress: 21.250%; Estimated time: 507.788 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 36 ------------------>\n",
      "Progress: 21.875%; Estimated time: 503.183 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 37 ------------------>\n",
      "Progress: 22.500%; Estimated time: 497.224 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 38 ------------------>\n",
      "Progress: 23.125%; Estimated time: 496.360 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 39 ------------------>\n",
      "Progress: 23.750%; Estimated time: 491.763 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 40 ------------------>\n",
      "Progress: 24.375%; Estimated time: 487.038 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 41 ------------------>\n",
      "Progress: 25.000%; Estimated time: 488.510 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 42 ------------------>\n",
      "Progress: 25.625%; Estimated time: 483.857 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 43 ------------------>\n",
      "Progress: 26.250%; Estimated time: 478.581 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 44 ------------------>\n",
      "Progress: 26.875%; Estimated time: 476.995 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 45 ------------------>\n",
      "Progress: 27.500%; Estimated time: 472.314 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 46 ------------------>\n",
      "Progress: 28.125%; Estimated time: 467.539 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 47 ------------------>\n",
      "Progress: 28.750%; Estimated time: 467.963 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 48 ------------------>\n",
      "Progress: 29.375%; Estimated time: 463.175 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 49 ------------------>\n",
      "Progress: 30.000%; Estimated time: 458.400 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 50 ------------------>\n",
      "Progress: 30.625%; Estimated time: 453.633 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 51 ------------------>\n",
      "Progress: 31.250%; Estimated time: 448.987 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 52 ------------------>\n",
      "Progress: 31.875%; Estimated time: 444.401 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 53 ------------------>\n",
      "Progress: 32.500%; Estimated time: 439.771 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 54 ------------------>\n",
      "Progress: 33.125%; Estimated time: 435.107 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 55 ------------------>\n",
      "Progress: 33.750%; Estimated time: 430.585 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 56 ------------------>\n",
      "Progress: 34.375%; Estimated time: 426.061 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 57 ------------------>\n",
      "Progress: 35.000%; Estimated time: 423.771 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 58 ------------------>\n",
      "Progress: 35.625%; Estimated time: 419.225 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 59 ------------------>\n",
      "Progress: 36.250%; Estimated time: 414.727 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 60 ------------------>\n",
      "Progress: 36.875%; Estimated time: 413.594 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 61 ------------------>\n",
      "Progress: 37.500%; Estimated time: 409.129 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 62 ------------------>\n",
      "Progress: 38.125%; Estimated time: 404.763 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 63 ------------------>\n",
      "Progress: 38.750%; Estimated time: 400.284 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'compression': 32}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 64 ------------------>\n",
      "Progress: 39.375%; Estimated time: 395.734 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'compression': 64}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 65 ------------------>\n",
      "Progress: 40.000%; Estimated time: 391.367 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 66 ------------------>\n",
      "Progress: 40.625%; Estimated time: 386.843 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 67 ------------------>\n",
      "Progress: 41.250%; Estimated time: 382.211 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 68 ------------------>\n",
      "Progress: 41.875%; Estimated time: 377.640 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 69 ------------------>\n",
      "Progress: 42.500%; Estimated time: 373.175 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 70 ------------------>\n",
      "Progress: 43.125%; Estimated time: 369.588 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 71 ------------------>\n",
      "Progress: 43.750%; Estimated time: 365.173 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 72 ------------------>\n",
      "Progress: 44.375%; Estimated time: 360.771 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 73 ------------------>\n",
      "Progress: 45.000%; Estimated time: 358.444 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 74 ------------------>\n",
      "Progress: 45.625%; Estimated time: 354.054 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 75 ------------------>\n",
      "Progress: 46.250%; Estimated time: 349.592 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 76 ------------------>\n",
      "Progress: 46.875%; Estimated time: 345.897 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 77 ------------------>\n",
      "Progress: 47.500%; Estimated time: 341.503 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 78 ------------------>\n",
      "Progress: 48.125%; Estimated time: 337.112 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 79 ------------------>\n",
      "Progress: 48.750%; Estimated time: 332.758 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 80 ------------------>\n",
      "Progress: 49.375%; Estimated time: 328.384 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 81 ------------------>\n",
      "Progress: 50.000%; Estimated time: 324.032 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 82 ------------------>\n",
      "Progress: 50.625%; Estimated time: 319.818 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 83 ------------------>\n",
      "Progress: 51.250%; Estimated time: 316.135 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 84 ------------------>\n",
      "Progress: 51.875%; Estimated time: 311.875 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 85 ------------------>\n",
      "Progress: 52.500%; Estimated time: 307.563 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 86 ------------------>\n",
      "Progress: 53.125%; Estimated time: 304.265 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 87 ------------------>\n",
      "Progress: 53.750%; Estimated time: 299.977 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 88 ------------------>\n",
      "Progress: 54.375%; Estimated time: 295.677 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 89 ------------------>\n",
      "Progress: 55.000%; Estimated time: 293.108 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 90 ------------------>\n",
      "Progress: 55.625%; Estimated time: 288.812 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 91 ------------------>\n",
      "Progress: 56.250%; Estimated time: 284.510 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 92 ------------------>\n",
      "Progress: 56.875%; Estimated time: 281.086 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 93 ------------------>\n",
      "Progress: 57.500%; Estimated time: 276.811 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 94 ------------------>\n",
      "Progress: 58.125%; Estimated time: 272.563 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 95 ------------------>\n",
      "Progress: 58.750%; Estimated time: 269.098 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 96 ------------------>\n",
      "Progress: 59.375%; Estimated time: 264.798 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 97 ------------------>\n",
      "Progress: 60.000%; Estimated time: 260.523 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 98 ------------------>\n",
      "Progress: 60.625%; Estimated time: 256.246 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 99 ------------------>\n",
      "Progress: 61.250%; Estimated time: 252.025 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 100 ------------------>\n",
      "Progress: 61.875%; Estimated time: 247.765 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 101 ------------------>\n",
      "Progress: 62.500%; Estimated time: 243.399 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 102 ------------------>\n",
      "Progress: 63.125%; Estimated time: 239.810 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 103 ------------------>\n",
      "Progress: 63.750%; Estimated time: 235.566 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 104 ------------------>\n",
      "Progress: 64.375%; Estimated time: 231.379 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 105 ------------------>\n",
      "Progress: 65.000%; Estimated time: 228.358 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 106 ------------------>\n",
      "Progress: 65.625%; Estimated time: 224.151 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 107 ------------------>\n",
      "Progress: 66.250%; Estimated time: 219.938 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 108 ------------------>\n",
      "Progress: 66.875%; Estimated time: 216.292 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 109 ------------------>\n",
      "Progress: 67.500%; Estimated time: 212.024 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 110 ------------------>\n",
      "Progress: 68.125%; Estimated time: 207.819 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 111 ------------------>\n",
      "Progress: 68.750%; Estimated time: 204.600 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 112 ------------------>\n",
      "Progress: 69.375%; Estimated time: 200.363 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 113 ------------------>\n",
      "Progress: 70.000%; Estimated time: 196.143 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 114 ------------------>\n",
      "Progress: 70.625%; Estimated time: 191.959 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 115 ------------------>\n",
      "Progress: 71.250%; Estimated time: 187.668 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 116 ------------------>\n",
      "Progress: 71.875%; Estimated time: 183.420 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 117 ------------------>\n",
      "Progress: 72.500%; Estimated time: 179.240 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 118 ------------------>\n",
      "Progress: 73.125%; Estimated time: 175.061 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 119 ------------------>\n",
      "Progress: 73.750%; Estimated time: 170.896 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 120 ------------------>\n",
      "Progress: 74.375%; Estimated time: 166.699 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 121 ------------------>\n",
      "Progress: 75.000%; Estimated time: 162.927 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 122 ------------------>\n",
      "Progress: 75.625%; Estimated time: 158.756 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 123 ------------------>\n",
      "Progress: 76.250%; Estimated time: 154.607 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 124 ------------------>\n",
      "Progress: 76.875%; Estimated time: 151.069 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 125 ------------------>\n",
      "Progress: 77.500%; Estimated time: 146.889 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 126 ------------------>\n",
      "Progress: 78.125%; Estimated time: 142.824 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 127 ------------------>\n",
      "Progress: 78.750%; Estimated time: 138.659 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 128 ------------------>\n",
      "Progress: 79.375%; Estimated time: 134.494 seconds\n",
      "Going through the following parameters: {'m': 8, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 129 ------------------>\n",
      "Progress: 80.000%; Estimated time: 130.335 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 130 ------------------>\n",
      "Progress: 80.625%; Estimated time: 126.706 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 131 ------------------>\n",
      "Progress: 81.250%; Estimated time: 122.540 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 132 ------------------>\n",
      "Progress: 81.875%; Estimated time: 118.405 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 133 ------------------>\n",
      "Progress: 82.500%; Estimated time: 114.499 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 134 ------------------>\n",
      "Progress: 83.125%; Estimated time: 110.353 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 135 ------------------>\n",
      "Progress: 83.750%; Estimated time: 106.200 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 136 ------------------>\n",
      "Progress: 84.375%; Estimated time: 102.063 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 137 ------------------>\n",
      "Progress: 85.000%; Estimated time: 97.943 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 138 ------------------>\n",
      "Progress: 85.625%; Estimated time: 93.826 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 139 ------------------>\n",
      "Progress: 86.250%; Estimated time: 89.700 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 140 ------------------>\n",
      "Progress: 86.875%; Estimated time: 85.574 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 141 ------------------>\n",
      "Progress: 87.500%; Estimated time: 81.461 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 142 ------------------>\n",
      "Progress: 88.125%; Estimated time: 77.350 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 143 ------------------>\n",
      "Progress: 88.750%; Estimated time: 73.384 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 144 ------------------>\n",
      "Progress: 89.375%; Estimated time: 69.262 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 16, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 145 ------------------>\n",
      "Progress: 90.000%; Estimated time: 65.156 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 146 ------------------>\n",
      "Progress: 90.625%; Estimated time: 61.271 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 147 ------------------>\n",
      "Progress: 91.250%; Estimated time: 57.158 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 148 ------------------>\n",
      "Progress: 91.875%; Estimated time: 53.048 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 1, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 149 ------------------>\n",
      "Progress: 92.500%; Estimated time: 49.032 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 150 ------------------>\n",
      "Progress: 93.125%; Estimated time: 44.928 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 151 ------------------>\n",
      "Progress: 93.750%; Estimated time: 40.827 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 152 ------------------>\n",
      "Progress: 94.375%; Estimated time: 36.853 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 16, 'oversampling': 4, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 153 ------------------>\n",
      "Progress: 95.000%; Estimated time: 32.742 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 154 ------------------>\n",
      "Progress: 95.625%; Estimated time: 28.633 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 155 ------------------>\n",
      "Progress: 96.250%; Estimated time: 24.572 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 156 ------------------>\n",
      "Progress: 96.875%; Estimated time: 20.468 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 1, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 157 ------------------>\n",
      "Progress: 97.500%; Estimated time: 16.367 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 158 ------------------>\n",
      "Progress: 98.125%; Estimated time: 12.269 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': False, 'quantile': 0.99}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 159 ------------------>\n",
      "Progress: 98.750%; Estimated time: 8.175 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'quantile': 0.95}\n",
      "Indexing finished for these params\n",
      "<------------------ ITERATION 160 ------------------>\n",
      "Progress: 99.375%; Estimated time: 4.086 seconds\n",
      "Going through the following parameters: {'m': 16, 'hnsw_ef': 64, 'ef_construct': 32, 'oversampling': 4, 'rescore': True, 'quantile': 0.99}\n",
      "Indexing finished for these params\n"
     ]
    }
   ],
   "source": [
    "results = grid_search_parameters(client=client,\n",
    "                                 golden_set_embeddings_path=\"dino_small_embeddings_men_casual.txt\",\n",
    "                                 df_list = [\n",
    "                                     pd.read_csv('combinations_product.csv').drop(columns=[\"Unnamed: 0\"]),\n",
    "                                     pd.read_csv('combinations_binary.csv').drop(columns=[\"Unnamed: 0\"]),\n",
    "                                     pd.read_csv('combinations_scalar.csv').drop(columns=[\"Unnamed: 0\"]),\n",
    "                                 ],\n",
    "                                 df_types= ['product', 'binary', 'scalar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83ceb347",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"results_{EMBEDDINGS_FILE}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f23a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_suitable = results[(results.precision_at_k >= 1.0) & (results.recall_at_k >= 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac9a235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>hnsw_ef</th>\n",
       "      <th>ef_construct</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>rescore</th>\n",
       "      <th>compression</th>\n",
       "      <th>time_elapsed_control_s</th>\n",
       "      <th>time_elapsed_test_s</th>\n",
       "      <th>local_cpu_perc_control_avg</th>\n",
       "      <th>local_cpu_perc_test_avg</th>\n",
       "      <th>local_ram_control_mb_avg</th>\n",
       "      <th>local_ram_test_mb_avg</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>ndcg_at_k</th>\n",
       "      <th>quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>0.450544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>109.929688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>0.531488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>108.695312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>0.571450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>1156.101562</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>0.614550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>109.148438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>2.858412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>109.414062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>2.886774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>111.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>2.895220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>1215.570312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>2.933762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>108.773438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464636</td>\n",
       "      <td>2.967646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1141.484375</td>\n",
       "      <td>110.687500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      m  hnsw_ef  ef_construct  oversampling  rescore  compression  \\\n",
       "35   16       16            16             1     True         64.0   \n",
       "99    8       16            16             1     True          NaN   \n",
       "113   8       64            16             1    False          NaN   \n",
       "0     8       16            16             1    False         32.0   \n",
       "41   16       16            32             1    False         64.0   \n",
       "..   ..      ...           ...           ...      ...          ...   \n",
       "144  16       64            16             1    False          NaN   \n",
       "150  16       64            16             4     True          NaN   \n",
       "128  16       16            16             1    False          NaN   \n",
       "109   8       16            32             4    False          NaN   \n",
       "103   8       16            16             4     True          NaN   \n",
       "\n",
       "     time_elapsed_control_s  time_elapsed_test_s  local_cpu_perc_control_avg  \\\n",
       "35                 0.464636             0.450544                         0.0   \n",
       "99                 0.464636             0.531488                         0.0   \n",
       "113                0.464636             0.551282                         0.0   \n",
       "0                  0.464636             0.571450                         0.0   \n",
       "41                 0.464636             0.614550                         0.0   \n",
       "..                      ...                  ...                         ...   \n",
       "144                0.464636             2.858412                         0.0   \n",
       "150                0.464636             2.886774                         0.0   \n",
       "128                0.464636             2.895220                         0.0   \n",
       "109                0.464636             2.933762                         0.0   \n",
       "103                0.464636             2.967646                         0.0   \n",
       "\n",
       "     local_cpu_perc_test_avg  local_ram_control_mb_avg  local_ram_test_mb_avg  \\\n",
       "35                       0.0               1141.484375             109.929688   \n",
       "99                       0.0               1141.484375             108.695312   \n",
       "113                      0.0               1141.484375             105.000000   \n",
       "0                        0.0               1141.484375            1156.101562   \n",
       "41                       0.0               1141.484375             109.148438   \n",
       "..                       ...                       ...                    ...   \n",
       "144                      0.0               1141.484375             109.414062   \n",
       "150                      0.0               1141.484375             111.500000   \n",
       "128                      0.0               1141.484375            1215.570312   \n",
       "109                      0.0               1141.484375             108.773438   \n",
       "103                      0.0               1141.484375             110.687500   \n",
       "\n",
       "     precision_at_k  recall_at_k  ndcg_at_k  quantile  \n",
       "35              1.0          1.0        1.0       NaN  \n",
       "99              1.0          1.0        1.0      0.99  \n",
       "113             1.0          1.0        1.0      0.99  \n",
       "0               1.0          1.0        1.0       NaN  \n",
       "41              1.0          1.0        1.0       NaN  \n",
       "..              ...          ...        ...       ...  \n",
       "144             1.0          1.0        1.0      0.95  \n",
       "150             1.0          1.0        1.0      0.95  \n",
       "128             1.0          1.0        1.0      0.95  \n",
       "109             1.0          1.0        1.0      0.99  \n",
       "103             1.0          1.0        1.0      0.99  \n",
       "\n",
       "[160 rows x 16 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_suitable_sorted = results_suitable.sort_values(by='time_elapsed_test_s', ascending=True)\n",
    "results_suitable_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9d62b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.update_collection(\n",
    "    collection_name = COLLECTION_NAME,\n",
    "        hnsw_config = models.HnswConfigDiff(\n",
    "            m = 8,\n",
    "            ef_construct = 32\n",
    "        ),\n",
    "        quantization_config=models.ScalarQuantization(\n",
    "            scalar=models.ScalarQuantizationConfig(\n",
    "                type=models.ScalarType.INT8,\n",
    "                quantile=0.95,\n",
    "                always_ram=True,\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "02a64d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=None, indexed_vectors_count=55680, points_count=62554, segments_count=6, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=768, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=8, ef_construct=32, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=0.95, always_ram=True))), payload_schema={'outfit_id': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=62554)})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(collection_name = COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "54bd679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_for_demo = search_similar(\"dino_base_embeddings_men_casual.txt\",\n",
    "               client,\n",
    "               search_params = models.SearchParams(hnsw_ef = 16, exact = False,\n",
    "                                    quantization=models.QuantizationSearchParams(\n",
    "                                    ignore = False, rescore = True, oversampling = 1)),\n",
    "               collection_name = COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c2c99943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'outfit_id': '9078',\n",
       "  'total_score': np.float64(105.59075819358918),\n",
       "  'matches': [{'wardrobe_image_index': 2,\n",
       "    'wardrobe_image_id': 'casual_men_tshirt_0',\n",
       "    'outfit_item_id': '22568b09-a5b5-4a3e-86ec-8369bd6d9982',\n",
       "    'score': 35.53486351614366},\n",
       "   {'wardrobe_image_index': 9,\n",
       "    'wardrobe_image_id': 'casual_men_boots_0',\n",
       "    'outfit_item_id': '90fa6f56-7eef-4664-857f-3832cf0dad74',\n",
       "    'score': 24.67156793179209},\n",
       "   {'wardrobe_image_index': 3,\n",
       "    'wardrobe_image_id': 'casual_men_pants_1',\n",
       "    'outfit_item_id': 'd97371b5-60cf-4105-b5fa-9ccebdebcd01',\n",
       "    'score': 32.09491485595089}]},\n",
       " {'outfit_id': '3610',\n",
       "  'total_score': np.float64(94.36473049896864),\n",
       "  'matches': [{'wardrobe_image_index': 9,\n",
       "    'wardrobe_image_id': 'casual_men_boots_0',\n",
       "    'outfit_item_id': '0b090248-8999-4638-8241-4048f32d640c',\n",
       "    'score': 17.81999637426704},\n",
       "   {'wardrobe_image_index': 3,\n",
       "    'wardrobe_image_id': 'casual_men_pants_1',\n",
       "    'outfit_item_id': '706d6730-a77e-4fd5-a993-2f898ad8203a',\n",
       "    'score': 22.553827186460634},\n",
       "   {'wardrobe_image_index': 1,\n",
       "    'wardrobe_image_id': 'casual_men_jacket_0',\n",
       "    'outfit_item_id': 'ec5ab41b-b4bc-4ad8-bf92-5df91d434877',\n",
       "    'score': 35.72327373623986},\n",
       "   {'wardrobe_image_index': 3,\n",
       "    'wardrobe_image_id': 'casual_men_pants_1',\n",
       "    'outfit_item_id': 'f97e6cb9-bdff-4e55-bb86-ccdf84c3a817',\n",
       "    'score': 18.26763320200111}]},\n",
       " {'outfit_id': '3092',\n",
       "  'total_score': np.float64(93.16910629099496),\n",
       "  'matches': [{'wardrobe_image_index': 9,\n",
       "    'wardrobe_image_id': 'casual_men_boots_0',\n",
       "    'outfit_item_id': '4b9d3a79-bc63-4c1e-b51c-d69ec7eed538',\n",
       "    'score': 20.3776718130876},\n",
       "   {'wardrobe_image_index': 1,\n",
       "    'wardrobe_image_id': 'casual_men_jacket_0',\n",
       "    'outfit_item_id': '6a4d3efd-080e-4852-a483-b7cf6a26c92f',\n",
       "    'score': 32.36750623181956},\n",
       "   {'wardrobe_image_index': 0,\n",
       "    'wardrobe_image_id': 'casual_men_pants_2',\n",
       "    'outfit_item_id': 'f5e446bc-91d0-4a1d-8251-391fb921c15c',\n",
       "    'score': 36.16104881772984}]},\n",
       " {'outfit_id': '10607',\n",
       "  'total_score': np.float64(93.02505184996295),\n",
       "  'matches': [{'wardrobe_image_index': 3,\n",
       "    'wardrobe_image_id': 'casual_men_pants_1',\n",
       "    'outfit_item_id': '41b8947f-9640-40a9-86bd-58eafa87319f',\n",
       "    'score': 34.48990334025094},\n",
       "   {'wardrobe_image_index': 6,\n",
       "    'wardrobe_image_id': 'casual_men_boots_1',\n",
       "    'outfit_item_id': '92f5632f-13b9-4c96-83b5-c42b43eacc5b',\n",
       "    'score': 24.643773370067127},\n",
       "   {'wardrobe_image_index': 2,\n",
       "    'wardrobe_image_id': 'casual_men_tshirt_0',\n",
       "    'outfit_item_id': 'fd5d23a0-ddf2-4ce1-adcc-f7a1b942e5ed',\n",
       "    'score': 33.89137513964487}]},\n",
       " {'outfit_id': '1647',\n",
       "  'total_score': np.float64(91.85275849715083),\n",
       "  'matches': [{'wardrobe_image_index': 9,\n",
       "    'wardrobe_image_id': 'casual_men_boots_0',\n",
       "    'outfit_item_id': '1f053321-da01-4aee-933c-c668220327de',\n",
       "    'score': 25.04800961371783},\n",
       "   {'wardrobe_image_index': 1,\n",
       "    'wardrobe_image_id': 'casual_men_jacket_0',\n",
       "    'outfit_item_id': '21ba3dad-7d41-4570-9405-2b1e007c1ed2',\n",
       "    'score': 36.655145012284756},\n",
       "   {'wardrobe_image_index': 3,\n",
       "    'wardrobe_image_id': 'casual_men_pants_1',\n",
       "    'outfit_item_id': '79a7f1b2-867e-4592-a211-acfddac401f3',\n",
       "    'score': 30.14960387114825}]}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_for_demo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
